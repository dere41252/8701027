<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>MediaPipe äººè‡‰åµæ¸¬</title>
    <style>
        body {
            margin: 0;
            padding: 20px;
            font-family: Arial, sans-serif;
        }
        #container {
            position: relative;
            width: 1280px;
            height: 720px;
        }
        #webcam {
            position: absolute;
            width: 1280px;
            height: 720px;
            transform: rotateY(180deg);
        }
        #output_canvas {
            position: absolute;
            width: 1280px;
            height: 720px;
            transform: rotateY(180deg);
        }
        #status {
            position: fixed;
            top: 10px;
            left: 10px;
            background-color: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 10px;
            border-radius: 5px;
            font-size: 14px;
            z-index: 1000;
        }
        .emoji {
            position: absolute;
            font-size: 150px;
            pointer-events: none;
        }
    </style>
</head>
<body>
    <div id="status">ç³»çµ±ç‹€æ…‹: åˆå§‹åŒ–ä¸­...</div>
    <div id="container">
        <video id="webcam" autoplay playsinline></video>
        <canvas id="output_canvas"></canvas>
    </div>

    <script type="module">
        import vision from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";
        const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;

        const video = document.getElementById("webcam");
        const canvas = document.getElementById("output_canvas");
        const ctx = canvas.getContext("2d");
        const statusDiv = document.getElementById("status");
        let faceLandmarker;
        let runningMode = "VIDEO";
        let lastVideoTime = -1;
        let results = undefined;

        // åŠ å…¥æ˜Ÿæ˜Ÿç›¸é—œçš„è®Šæ•¸
        let stars = [];
        const GRAVITY = 0.5;
        const STAR_LIFETIME = 2000; // æ˜Ÿæ˜Ÿå­˜æ´»æ™‚é–“ï¼ˆæ¯«ç§’ï¼‰
        const STARS_PER_SECOND = 20;
        let lastStarTime = 0;

        // æ˜Ÿæ˜Ÿé¡åˆ¥
        class Star {
            constructor(x, y) {
                this.x = x;
                this.y = y;
                this.vx = (Math.random() - 0.5) * 10; // æ°´å¹³åˆé€Ÿåº¦
                this.vy = -Math.random() * 10 - 5;    // å‚ç›´åˆé€Ÿåº¦
                this.opacity = 1;
                this.birth = performance.now();
            }

            update() {
                this.x += this.vx;
                this.y += this.vy;
                this.vy += GRAVITY;
                
                const age = performance.now() - this.birth;
                this.opacity = 1 - (age / STAR_LIFETIME);
            }

            draw(ctx) {
                ctx.save();
                ctx.fillStyle = `rgba(255, 255, 0, ${this.opacity})`;
                ctx.font = "20px Arial";
                ctx.fillText("â­", this.x, this.y);
                ctx.restore();
            }
        }

        // æ›´æ–°ç‹€æ…‹é¡¯ç¤º
        function updateStatus(message) {
            statusDiv.textContent = "ç³»çµ±ç‹€æ…‹: " + message;
        }

        // éŒ¯èª¤è™•ç†
        function handleError(error) {
            console.error(error);
            updateStatus("éŒ¯èª¤: " + error.message);
        }

        // åˆå§‹åŒ– FaceLandmarker
        async function initializeFaceLandmarker() {
            try {
                updateStatus("è¼‰å…¥æ¨¡å‹ä¸­...");
                const filesetResolver = await FilesetResolver.forVisionTasks(
                    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
                );
                faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                    baseOptions: {
                        modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
                        delegate: "GPU"
                    },
                    outputFaceBlendshapes: true,
                    runningMode,
                    numFaces: 1
                });
                updateStatus("æ¨¡å‹è¼‰å…¥å®Œæˆ");
                startCamera();
            } catch (error) {
                handleError(error);
            }
        }

        // å•Ÿå‹•æ”å½±æ©Ÿ
        async function startCamera() {
            try {
                updateStatus("å•Ÿå‹•æ”å½±æ©Ÿä¸­...");
                const constraints = {
                    video: {
                        width: 1280,
                        height: 720
                    }
                };
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                video.addEventListener("loadeddata", predictWebcam);
                canvas.width = 1280;
                canvas.height = 720;
                updateStatus("æ”å½±æ©Ÿå•Ÿå‹•æˆåŠŸ");
            } catch (error) {
                handleError(error);
            }
        }

        // é æ¸¬å’Œç¹ªè£½
        async function predictWebcam() {
            const drawingUtils = new DrawingUtils(ctx);

            // æ¸…é™¤ç•«å¸ƒ
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            if (lastVideoTime !== video.currentTime) {
                lastVideoTime = video.currentTime;
                results = faceLandmarker.detectForVideo(video, performance.now());
            }

            if (results.faceLandmarks) {
                for (const landmarks of results.faceLandmarks) {
                    // åªç¹ªè£½çœ¼ç›å’Œå˜´å·´çš„è¼ªå»“
                    drawingUtils.drawConnectors(
                        landmarks,
                        FaceLandmarker.FACE_LANDMARKS_RIGHT_EYE,
                        { color: "#FF3030" }
                    );
                    drawingUtils.drawConnectors(
                        landmarks,
                        FaceLandmarker.FACE_LANDMARKS_LEFT_EYE,
                        { color: "#30FF30" }
                    );

                    // ç¹ªè£½ emoji çœ¼ç›
                    const leftEye = landmarks[159]; // å·¦çœ¼ä¸­å¿ƒé»
                    const rightEye = landmarks[386]; // å³çœ¼ä¸­å¿ƒé»
                    
                    ctx.font = "150px Arial";
                    ctx.fillText("ğŸ³", leftEye.x * canvas.width - 75, leftEye.y * canvas.height + 75);
                    ctx.fillText("ğŸ‘§", rightEye.x * canvas.width - 75, rightEye.y * canvas.height + 75);

                    // æª¢æ¸¬å˜´å·´æ˜¯å¦å¼µé–‹
                    const upperLip = landmarks[13];  // ä¸Šå”‡ä¸­é»
                    const lowerLip = landmarks[14];  // ä¸‹å”‡ä¸­é»
                    const mouthOpen = (lowerLip.y - upperLip.y) * canvas.height > 30; // èª¿æ•´é–¾å€¼

                    if (mouthOpen) {
                        const now = performance.now();
                        if (now - lastStarTime > (1000 / STARS_PER_SECOND)) {
                            stars.push(new Star(
                                (upperLip.x + lowerLip.x) * canvas.width / 2,
                                (upperLip.y + lowerLip.y) * canvas.height / 2
                            ));
                            lastStarTime = now;
                        }
                    }
                }
                updateStatus("åµæ¸¬åˆ°äººè‡‰");
            } else {
                updateStatus("æœªåµæ¸¬åˆ°äººè‡‰");
            }

            // æ›´æ–°å’Œç¹ªè£½æ‰€æœ‰æ˜Ÿæ˜Ÿ
            stars = stars.filter(star => star.opacity > 0);
            stars.forEach(star => {
                star.update();
                star.draw(ctx);
            });

            // æŒçºŒåŸ·ï¿½ï¿½ï¿½é æ¸¬
            window.requestAnimationFrame(predictWebcam);
        }

        // å•Ÿå‹•ç¨‹å¼
        initializeFaceLandmarker();
    </script>
</body>
</html>
